{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4t79o9WoJdE",
        "outputId": "00fabcb9-0f60-4576-cae5-927203cd8fbe"
      },
      "id": "c4t79o9WoJdE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ff04ff-2f03-4c1b-8f94-5c0fff5bbd24",
      "metadata": {
        "id": "13ff04ff-2f03-4c1b-8f94-5c0fff5bbd24"
      },
      "source": [
        "# Question-1\n",
        "Write a Python code to build a deep neural network using Keras and compute a number of parameters, memory and FLOPs for the following model. Use relu activations functions in the hidden layers and sigmoid activations function in the output layers.\n",
        "\n",
        "\n",
        "CPU that performs 1 GFLOPS (1,000,000,000) per seconds and computes the inference time of the Deep neural network model.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"2.png\" width=\"700\" height=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3bbfd46-dc1d-403b-bde7-5daab5627172",
      "metadata": {
        "id": "a3bbfd46-dc1d-403b-bde7-5daab5627172"
      },
      "source": [
        "##  Parameters calculation in Deep neural network\n",
        "\n",
        "The number of internal parameters in a neural network is the total number of weights + the total number of biases. The total number of weights equals the sum of the products of each pair of adjacent layers. The total number of biases equals the number of hidden neurons + the number of output neurons.\n",
        "\n",
        "## Model Size calculations\n",
        "\n",
        "\n",
        "Model Size (in bytes)=Number of Parameters×Bytes Per Parameter\n",
        "Model Size (in KB)=Model Size (in bytes)/1024\n",
        "\n",
        "##  FLOPs calculation in Deep neural network\n",
        "FLOPs of  FC=2*(input size x output size )+(output size x activation)\n",
        "\n",
        "## Activation functions FLOPS for  Tensor Flow\n",
        "\n",
        "Relu  -->      1FLOPs\n",
        "\n",
        "Sigmoid   -->   1FLOPs\n",
        "\n",
        "Tanh   -->      1FLOPs\n",
        "\n",
        "Softmax    -->  6FLOPs\n",
        "\n",
        "## Infrences time calculations\n",
        "\n",
        "The inference time = FLOPs/FLOPS.\n",
        "\n",
        "FLOPs-> measures computational complexity of the model.\n",
        "\n",
        "FLOPS-> measures the hardware’s processing capability\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bc661c-0608-479a-a379-ce4f7a7a1712",
      "metadata": {
        "id": "50bc661c-0608-479a-a379-ce4f7a7a1712"
      },
      "outputs": [],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential((Dense(5,activation=\"relu\",input_shape=(5,)),Dense(5,activation=\"relu\"),Dense(1,activation=\"relu\"),))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukefOedCpD8x",
        "outputId": "ef51a090-0b14-4550-f3c8-43ebcb3c46a5"
      },
      "id": "ukefOedCpD8x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "  totparm=0\n",
        "  totflops=0\n",
        "  for layer in model.layers:\n",
        "    layertype=layer.__class__.__name__\n",
        "    if layertype in [\"Dense\"]:\n",
        "      inputunit=layer.input.shape[-1] # Accessing input shape using layer.input\n",
        "      outputunit=layer.output.shape[-1]# Accessing input shape using layer.output\n",
        "      parm=inputunit*outputunit+outputunit\n",
        "      flops=2*inputunit*outputunit\n",
        "      totparm=totparm+parm\n",
        "      totflops=totflops+flops\n",
        "  return totparm,totflops"
      ],
      "metadata": {
        "id": "mj_htU-JpGWK"
      },
      "id": "mj_htU-JpGWK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p,f=compute(model)\n",
        "print(p)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijZqireOpIyK",
        "outputId": "5fc1361b-9b38-4f0c-ce1e-54cda74839f1"
      },
      "id": "ijZqireOpIyK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcca70a6-efbd-4ec7-a94c-2fc83072a07b",
      "metadata": {
        "id": "dcca70a6-efbd-4ec7-a94c-2fc83072a07b"
      },
      "source": [
        "# Question-2\n",
        "Write a Python code to build a deep neural network using Keras and compute a number of parameters, memory and FLOPs for the following model. Use relu activations functions in the hidden layers and softmax activations function in the output layers. Write a Python code plot  the bar graph of the question 1 and question 2 output and compare.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"1.png\" width=\"700\" height=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a795d48-531a-4917-b708-dd9af3f2f2cd",
      "metadata": {
        "id": "1a795d48-531a-4917-b708-dd9af3f2f2cd"
      },
      "outputs": [],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential((Dense(9,activation=\"relu\",input_shape=(4,)),Dense(6,activation=\"relu\"),Dense(3,activation=\"relu\"),))"
      ],
      "metadata": {
        "id": "Rz637IVgpXzt"
      },
      "id": "Rz637IVgpXzt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model2):\n",
        "  totparm=0\n",
        "  totflops=0\n",
        "  for layer in model.layers:\n",
        "    layertype=layer.__class__.__name__\n",
        "    if layertype in [\"Dense\"]:\n",
        "      inputunit=layer.input.shape[-1] # Accessing input shape using layer.input\n",
        "      outputunit=layer.output.shape[-1]# Accessing input shape using layer.output\n",
        "      parm=inputunit*outputunit+outputunit\n",
        "      flops=2*inputunit*outputunit\n",
        "      totparm=totparm+parm\n",
        "      totflops=totflops+flops\n",
        "  return totparm,totflops"
      ],
      "metadata": {
        "id": "CCRWJ5LopcIn"
      },
      "id": "CCRWJ5LopcIn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p,f=compute(model)\n",
        "print(p)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGdM0t_YpgF6",
        "outputId": "d407a1c8-7fcc-4f88-f46e-8a4c4db710a2"
      },
      "id": "hGdM0t_YpgF6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126\n",
            "216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f4995f-d746-4d7d-98eb-5cf732c02fac",
      "metadata": {
        "id": "96f4995f-d746-4d7d-98eb-5cf732c02fac"
      },
      "source": [
        "## Output Dimensions Formula for 2D Convolution\n",
        "<img src=\"10.png\" width=\"600\" height=\"400\">\n",
        "\n",
        "## Parameter calculation of 2DCNN\n",
        "\n",
        "\n",
        "<img src=\"4.png\" width=\"400\" height=\"200\">\n",
        "\n",
        "## FLOPs calculation of 2DCNN\n",
        "<img src=\"6.png\" width=\"600\" height=\"400\">\n",
        "\n",
        "\n",
        "\n",
        "## FLOPs calculation for Pooling Layers\n",
        "<img src=\"12.png\" width=\"600\" height=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec5bed0-e48b-472c-82d8-c84fcb7bb443",
      "metadata": {
        "id": "bec5bed0-e48b-472c-82d8-c84fcb7bb443"
      },
      "source": [
        "# Question-3\n",
        "\n",
        "Write a Python code build 2DCNN model for the following specifications using Keras and compute the number of parameters ,model size and FLOPs\n",
        "\n",
        "The model architecture consists of several layers designed for image classification tasks, such as recognizing digits from the MNIST dataset. The architecture begins with a 2D convolutional layer (Conv2D), which applies 32 filters of size 3x3 to the input image (28x28x1), followed by the ReLU activation function to introduce non-linearity. This is followed by a max-pooling layer (MaxPooling2D) with a pool size of 2x2, reducing the spatial dimensions of the feature maps while retaining important information. A second convolutional layer with 64 filters of size 3x3 is then applied, again using ReLU activation. Another max-pooling layer  (2x2 ) follows to further downsample the feature maps. The output of the convolutional layers is then flattened into a one-dimensional vector using the Flatten layer, which is fed into the fully connected dense layers. The first dense layer has 64 neurons with ReLU activation, allowing the model to learn complex representations, while the final dense layer has 10 neurons with a softmax activation function, providing probabilities for each of the 10 possible digit classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JTnoFaLw1fPE"
      },
      "id": "JTnoFaLw1fPE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0140dc76-f695-41d3-bd81-b0627fd9950e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0140dc76-f695-41d3-bd81-b0627fd9950e",
        "outputId": "d27d7eb7-60cc-4822-ca34-24852d76afa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 121930\n",
            "Total FLOPs: 5056000\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Function to compute parameters and FLOPs\n",
        "def compute(model):\n",
        "    totparm = 0\n",
        "    totflops = 0\n",
        "\n",
        "    # Build the model to get output shapes\n",
        "    model.build(input_shape=(None, 28, 28, 1))\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layertype = layer.__class__.__name__\n",
        "\n",
        "        if layertype == \"Dense\":\n",
        "            inputunit = layer.input.shape[-1]  # Accessing input shape using layer.input\n",
        "            outputunit = layer.output.shape[-1]  # Accessing output shape using layer.output\n",
        "            parm = inputunit * outputunit + outputunit  # Parameters: (input_units * output_units) + output_units (bias)\n",
        "            flops = 2 * inputunit * outputunit  # FLOPs for Dense: input_units * output_units * 2\n",
        "            totparm += parm\n",
        "            totflops += flops\n",
        "\n",
        "        elif layertype == \"Conv2D\":\n",
        "            # Get the input channels, output channels, and kernel size\n",
        "            input_channels = layer.input.shape[-1]  # Number of input channels (depth of input)\n",
        "            output_channels = layer.filters  # Number of filters (output channels)\n",
        "            kernel_size = layer.kernel_size[0] * layer.kernel_size[1]  # Kernel size (height * width)\n",
        "\n",
        "            # Compute output shape of Conv2D layer manually\n",
        "            input_height, input_width = layer.input.shape[1], layer.input.shape[2]  # Input height and width\n",
        "            output_height = (input_height - layer.kernel_size[0]) // layer.strides[0] + 1\n",
        "            output_width = (input_width - layer.kernel_size[1]) // layer.strides[1] + 1\n",
        "\n",
        "            # FLOPs for Conv2D: kernel_height * kernel_width * input_channels * output_channels * output_height * output_width * 2 (multiplications + additions)\n",
        "            flops = 2 * kernel_size * input_channels * output_channels * output_height * output_width\n",
        "            totflops += flops\n",
        "\n",
        "            # Parameters for Conv2D: (kernel_height * kernel_width * input_channels * output_channels) + output_channels (bias)\n",
        "            parm = kernel_size * input_channels * output_channels + output_channels\n",
        "            totparm += parm\n",
        "\n",
        "    return totparm, totflops\n",
        "\n",
        "# Compute the total parameters and FLOPs for the model\n",
        "total_params, total_flops = compute(model)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total parameters: {total_params}\")  # Expected: 121930\n",
        "print(f\"Total FLOPs: {total_flops}\")  # Expected: 5106520\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07efdcc1-e0dc-493a-9a6a-e76c2e6b4920",
      "metadata": {
        "id": "07efdcc1-e0dc-493a-9a6a-e76c2e6b4920"
      },
      "source": [
        "# Question-4\n",
        "Write a Python code to build CNN using Keras and compute a  number of parameters,memory and FLOPs for the following model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"3.jpg\" width=\"900\" height=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297ed5e3-c963-43c6-a6ea-063fffe67231",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "297ed5e3-c963-43c6-a6ea-063fffe67231",
        "outputId": "405612b0-5fd2-4bcb-c69b-87939dd13bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m147,520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m167,562\u001b[0m (654.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,562</span> (654.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m167,562\u001b[0m (654.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,562</span> (654.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Write  your code here\n",
        "### Write  your code here\n",
        "\n",
        "model4=Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(10,activation=\"softmax\")\n",
        "])\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81bd615b-8d3f-40a3-b174-e2879460c4c3",
      "metadata": {
        "id": "81bd615b-8d3f-40a3-b174-e2879460c4c3"
      },
      "source": [
        "## Output Shape of 3DCNN\n",
        "\n",
        "<img src=\"13.png\" width=\"400\" height=\"300\">\n",
        "<img src=\"14.png\" width=\"400\" height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3DCNN parameters calculations\n",
        "<img src=\"7.png\" width=\"900\" height=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c329993c-6a36-493f-9e05-b4ee86005753",
      "metadata": {
        "id": "c329993c-6a36-493f-9e05-b4ee86005753"
      },
      "source": [
        "### 3DCNN FLOPs calculations\n",
        "\n",
        "<img src=\"8.png\" width=\"900\" height=\"700\">\n",
        "\n",
        "\n",
        "\n",
        "### 3DCNN FLOPs calculation for Pooling Layers\n",
        "<img src=\"15.png\" width=\"900\" height=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e700ae-b194-434f-826c-1e8183acc37e",
      "metadata": {
        "id": "57e700ae-b194-434f-826c-1e8183acc37e"
      },
      "source": [
        "# Question-5\n",
        "\n",
        "You are tasked with designing a 3D Convolutional Neural Network (3D CNN) to classify video clips into one of five categories, such as walking, running, jumping, swimming, and cycling. Each video clip consists of 16 frames of size 64x64, and the data has a single channel (grayscale). The model should include two 3D convolutional layers followed by max-pooling layers, a flattening layer, and fully connected dense layers. Specifically, the architecture should satisfy the following requirements:\n",
        "\n",
        "The input layer should accept a shape of (16, 64, 64, 1) corresponding to the temporal, height, width, and channel dimensions.\n",
        "The first 3D convolutional layer should have 32 filters of size (3, 3, 3) and use ReLU activation.\n",
        "The first max-pooling layer should have a pool size of (2, 2, 2) to downsample the feature maps.\n",
        "The second 3D convolutional layer should have 64 filters of size (3, 3, 3) and use ReLU activation.\n",
        "The second max-pooling layer should again have a pool size of (2, 2, 2).\n",
        "The flattened layer should connect to a dense layer with 128 neurons using ReLU activation, followed by the output layer with 5 neurons and a softmax activation.\n",
        "Design and implement this 3D CNN architecture, compute the number of parameters for each layer, compute the model size and compute the FLOPs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dee948f-5288-4fbc-b995-443a3d975263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "6dee948f-5288-4fbc-b995-443a3d975263",
        "outputId": "cac199f4-a996-44be-bbba-bc0286995c89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,268,293\u001b[0m (12.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,268,293</span> (12.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,268,293\u001b[0m (12.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,268,293</span> (12.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(16, 64, 64, 1)),\n",
        "    layers.MaxPooling3D((2, 2, 2)),\n",
        "    layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
        "    layers.MaxPooling3D((2, 2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Summary of the model to get parameters\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0457d1f-bca5-405f-8dd3-2fbc26dd7038",
      "metadata": {
        "id": "d0457d1f-bca5-405f-8dd3-2fbc26dd7038"
      },
      "source": [
        "# Question-6\n",
        "\n",
        "A company is building a system to predict customer sentiment (positive or negative) based on a sequence of customer reviews.\n",
        "Each review is represented as a feature vector of size 4, where each feature corresponds to a specific aspect of the review, such as tone, length, and keyword presence. To process this sequential data, the team decides to use a Recurrent Neural Network (RNN).\n",
        "\n",
        "The input size n<sub>x</sub> is 4, meaning each input vector x<sup>t</sup> has 4 features.  \n",
        "The hidden layer has 3 hidden units n<sub>a</sub>=3.  \n",
        "The output size n<sub>y</sub> is 2, corresponding to the two possible sentiment classes (positive or negative).  \n",
        "The sequence length T<sub>x</sub> is 5, meaning the RNN will process a sequence of 5 reviews at a time.\n",
        "use sigmoid activation functions in the output layers and compute the number of parameters and memory in the RNN model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"9.png\" width=\"300\" height=\"100\">\n",
        "\n",
        "\n",
        "Number of parameter of RNN = g × [a(a+i) + a]\n",
        "\n",
        "a --> hidden unit\n",
        "\n",
        "i ---> input unit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77c1ac0-6a30-46c5-93d8-e78f34284ae6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "e77c1ac0-6a30-46c5-93d8-e78f34284ae6",
        "outputId": "76750eb1-a772-4f7f-ac5b-1450fc9179ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m24\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 32\n",
            "Memory required for the parameters: 128 bytes\n"
          ]
        }
      ],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    # RNN layer with 3 hidden units and 4 input features (nx = 4)\n",
        "    layers.SimpleRNN(3, input_shape=(5, 4), activation='tanh', return_sequences=False),\n",
        "    # Output layer with 2 neurons (for binary sentiment classification)\n",
        "    layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model summary to check the number of parameters\n",
        "model.summary()\n",
        "\n",
        "# Calculate and print the number of parameters and memory\n",
        "def compute_parameters_and_memory(model):\n",
        "    # Total parameters in the model\n",
        "    total_params = model.count_params()\n",
        "\n",
        "    # Memory usage (in bytes) for the parameters (assuming 4 bytes per parameter)\n",
        "    memory_usage = total_params * 4  # 4 bytes per parameter (float32)\n",
        "\n",
        "    return total_params, memory_usage\n",
        "\n",
        "# Get the number of parameters and memory usage\n",
        "total_params, memory_usage = compute_parameters_and_memory(model)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "print(f\"Memory required for the parameters: {memory_usage} bytes\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1933955e-5b05-4e2e-9b36-27b5190fea54",
      "metadata": {
        "id": "1933955e-5b05-4e2e-9b36-27b5190fea54"
      },
      "source": [
        "# Question 7\n",
        "\n",
        "Write a Python code to implement a single LSTM unit for the follwoing and compute the parameter of the follwoing model using Keras.\n",
        "    \n",
        "<img src=\"https://github.com/kmkarakaya/ML_tutorials/blob/master/images/LSTM_internal2.png?raw=true\" width=\"500\">\n",
        "\n",
        "\n",
        " Notice that we can guess the size (shape) of W,U and b given:\n",
        " * Input size ($h_{t-1}$ and $x_{t}$ )\n",
        " * Output size ($h_{t-1}$)\n",
        "\n",
        " Since output must equal to Hidden State (hx1) size:\n",
        "\n",
        "  * for W param =  ($h$ × $x$)\n",
        "  * for U param =  ($h$ × $h$)\n",
        "  * for Biases  param =   $h$\n",
        "\n",
        " * total params = W param + U param + Biases param\n",
        "  \n",
        "    =  ($h$ × $x$) +  ($h$ × $h$) +  $h$\n",
        "\n",
        "    =  ( ($h$ × $x$) +  ($h$ × $h$) +   $h$ )\n",
        "\n",
        "    =  ( ($x$ + $h$) ×  $h$  +   $h$ )\n",
        "\n",
        "* there are 4 functions which are exactly defined in the same way, in the LSTM layer, there will be\n",
        "\n",
        " ##   **LSTM parameter number = 4 × (($x$ + $h$) × $h$ +$h$)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32110225-3e3a-482c-a850-835920d0fda8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "32110225-3e3a-482c-a850-835920d0fda8",
        "outputId": "787619c8-efdc-40f5-aeca-cb5507510d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m96\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters in the LSTM unit: 96\n"
          ]
        }
      ],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the LSTM model with a single LSTM unit\n",
        "input_size = 4  # Number of features in the input vector (x)\n",
        "hidden_units = 3  # Number of hidden units in the LSTM layer (h)\n",
        "\n",
        "# Build the model with one LSTM unit\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(hidden_units, input_shape=(None, input_size), return_sequences=False)\n",
        "])\n",
        "\n",
        "# Print model summary to see the number of parameters\n",
        "model.summary()\n",
        "\n",
        "# Function to calculate number of parameters for a single LSTM unit\n",
        "def compute_lstm_parameters(input_size, hidden_units):\n",
        "    # Number of parameters in a single LSTM unit\n",
        "    params_per_gate = (input_size + hidden_units) * hidden_units + hidden_units\n",
        "    total_params = 4 * params_per_gate  # Four gates (input, forget, cell, output)\n",
        "\n",
        "    return total_params\n",
        "\n",
        "# Compute the number of parameters\n",
        "total_lstm_params = compute_lstm_parameters(input_size, hidden_units)\n",
        "\n",
        "# Print the calculated total parameters\n",
        "print(f\"Total parameters in the LSTM unit: {total_lstm_params}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}